# ðŸŒŸ DBT Star Schema Project â€” End-to-End Data Modeling with Snowflake

## ðŸ“˜ Overview

This project demonstrates a **complete end-to-end DBT workflow** â€” from staging raw data to building fact and dimension tables, adding seeds, macros, and data quality tests.
It follows a **Star Schema** design and simulates a **real-world analytics engineering setup** used in modern data teams.

Built using **dbt Core + Snowflake**, this project transforms raw data into analytics-ready models with robust testing and documentation.

---

## ðŸ§± Architecture Overview

**Flow:**

```
Raw Data â†’ Staging Models â†’ Dimension Tables â†’ Fact Table â†’ Tests â†’ Docs
```

**Schema Layers:**

| Layer               | Purpose                               | Example Models                                            |
| ------------------- | ------------------------------------- | --------------------------------------------------------- |
| `staging/`          | Clean and standardize raw source data | `stg_orders.sql`, `stg_customers.sql`, `stg_products.sql` |
| `marts/dimensions/` | Create reusable dimension tables      | `dim_customers.sql`, `dim_products.sql`                   |
| `marts/`            | Build fact table joining dimensions   | `fct_sales.sql`                                           |
| `snapshots/`        | Track changes over time (SCD)         | `customers_snapshot.sql`                                  |
| `seeds/`            | Load static lookup tables from CSV    | `product_categories.csv`                                  |
| `macros/`           | Define reusable SQL logic             | `category_cleaning.sql`, `positive_sales.sql`             |
| `tests/`            | Add data quality & integrity checks   | (optional folder, now handled via macros)                 |

---

## ðŸ§© Key Components

### ðŸ§  1. Staging Models

Located in `models/staging/`:

* Cleans raw source data (`orders`, `customers`, `products`).
* Applies consistent naming conventions, type casting, and basic transformations.
* Serves as the foundation for dimension and fact models.

---

### ðŸ“Š 2. Dimension & Fact Models

Located in `models/marts/`:

* **Fact Table:** `fct_sales` joins customers, products, and orders into one analytical table.
* **Dimensions:**

  * `dim_customers` â€“ Customer information
  * `dim_products` â€“ Product information enriched via seeds

Implements a **Star Schema** â€” enabling efficient analytical queries.

---

### ðŸŒ± 3. Seeds

Static lookup data stored in `seeds/product_categories.csv`:

* Loaded using:

  ```bash
  dbt seed
  ```

* Joined to dimension tables for enriched categorization.

---

### ðŸª„ 4. Macros

Reusable SQL logic defined in `macros/category_cleaning.sql`, allowing transformations like category formatting to be applied across multiple models.

---

### ðŸ§ª 5. Tests

Includes both **generic** and **custom macro-based tests**.

#### âœ… Example: Generic Tests

Defined in `schema.yml`:

```yaml
tests:
  - not_null
  - unique
```

#### ðŸ§© Example: Custom Macro Test

ðŸ“‚ File: `macros/positive_sales.sql`

```sql
{% test positive_sales(model, column_name) %}
select *
from {{ model }}
where {{ column_name }} <= 0
{% endtest %}
```

Then reference it inside `schema.yml` (e.g., for `fct_sales`):

```yaml
models:
  - name: fct_sales
    columns:
      - name: amount_usd
        tests:
          - not_null
          - positive_sales
```

Run all tests:

```bash
dbt test
```

âœ… This ensures all sales amounts are positive and showcases the **modern way to create custom DBT tests using macros.**

---

### ðŸ§¾ 6. Snapshots

`customers_snapshot.sql` tracks customer attribute changes over time:

```sql
{% snapshot customers_snapshot %}
{{ config(
    target_schema='snapshots',
    unique_key='customer_id',
    strategy='timestamp',
    updated_at='updated_at'
) }}
select * from {{ ref('stg_customers') }}
{% endsnapshot %}
```

---

## âš™ï¸ Commands Used

| Command             | Purpose                         |
| ------------------- | ------------------------------- |
| `dbt run`           | Executes models                 |
| `dbt build`         | Runs models + tests + snapshots |
| `dbt test`          | Runs all data tests             |
| `dbt seed`          | Loads CSV files as tables       |
| `dbt snapshot`      | Tracks historical changes       |
| `dbt docs generate` | Builds model documentation      |
| `dbt docs serve`    | Opens interactive lineage graph |

---

Perfect ðŸ‘Œ hereâ€™s the **ðŸ§© â€œHow It Worksâ€** section you can drop right before the **â€œðŸ“Š Documentation & Lineageâ€** section in your README â€” itâ€™s formatted to look great on GitHub:

---

## ðŸ§© How It Works â€” Data Flow Overview

This diagram shows how raw data moves through the DBT pipeline and becomes analytics-ready in your **Star Schema** model.

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        Raw Data           â”‚
        â”‚ (orders, customers, etc.) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Staging Models       â”‚
        â”‚ (stg_orders, stg_customersâ”‚
        â”‚  stg_products)            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Dimension Tables         â”‚
        â”‚ (dim_customers, dim_products) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        Fact Table         â”‚
        â”‚         fct_sales         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        DBT Tests          â”‚
        â”‚ (generic + macro-based)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Analytics Layer       â”‚
        â”‚ (Power BI / Tableau / BI) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Purpose:**
Each stage ensures clean, validated, and enriched data ready for dashboards and business insights.

---

## ðŸ“Š Documentation & Lineage

You can visualize the entire pipeline using:

```bash
dbt docs generate
dbt docs serve
```

This opens an interactive UI showing:

* Model dependencies
* Data lineage graph
* Table documentation (from `schema.yml`)

---

## ðŸ“ Final Folder Structure

```
models/
 â”œâ”€â”€ sources.yml
 â”œâ”€â”€ staging/
 â”‚    â”œâ”€â”€ stg_orders.sql
 â”‚    â”œâ”€â”€ stg_customers.sql
 â”‚    â””â”€â”€ stg_products.sql
 â”œâ”€â”€ marts/
 â”‚    â”œâ”€â”€ schema.yml
 â”‚    â”œâ”€â”€ dimensions/
 â”‚    â”‚    â”œâ”€â”€ dim_customers.sql
 â”‚    â”‚    â””â”€â”€ dim_products.sql
 â”‚    â””â”€â”€ fct_sales.sql
snapshots/
 â””â”€â”€ customers_snapshot.sql
seeds/
 â””â”€â”€ product_categories.csv
macros/
 â”œâ”€â”€ category_cleaning.sql
 â””â”€â”€ positive_sales.sql
```

---

## ðŸ’¡ Key Learnings

| Concept           | Description                                              |
| ----------------- | -------------------------------------------------------- |
| **Data Modeling** | Built a layered model structure (staging â†’ marts).       |
| **Star Schema**   | Designed a central fact with dimension relationships.    |
| **Seeds**         | Used static lookup data to enrich models.                |
| **Macros**        | Implemented reusable SQL logic and custom tests.         |
| **Testing**       | Added generic & macro-based data quality tests.          |
| **Snapshots**     | Captured historical SCD2-style data changes.             |
| **Docs**          | Generated data lineage and documentation using dbt docs. |

---

## ðŸš€ Real-World Relevance

This project mirrors **real analytics engineering practices** used in organizations like Airbnb, Snowflake, and dbt Labs:

* Implements modular, version-controlled data pipelines.
* Enforces data quality and governance.
* Follows ELT principles with scalable design.
* Prepares clean, analytics-ready datasets for BI tools like Power BI or Tableau.

---

## ðŸ§° Tech Stack

| Tool            | Purpose                       |
| --------------- | ----------------------------- |
| **DBT Core**    | Data transformation framework |
| **Snowflake**   | Cloud data warehouse          |
| **Jinja + SQL** | Templated transformations     |
| **YAML**        | Schema & test configurations  |
| **GitHub**      | Version control and portfolio |

---

## ðŸ§  Learning Outcomes

By completing this project, you mastered:

* Structuring dbt projects using **staging â†’ marts â†’ tests**
* Designing **Star Schema** models in dbt
* Creating **macros**, **seeds**, and **snapshots**
* Implementing **data quality testing using macros**
* Using **dbt docs** for visualization and governance

---

## ðŸŽ¯ Next Steps

If you wish to extend this project:

1. Add **incremental models** for large datasets
2. Automate `dbt build` with **GitHub Actions**
3. Connect outputs to **Power BI / Tableau dashboards**
4. Experiment with **exposures** for data lineage tracking

---

âœ… **This project is now production-style and portfolio-ready!**

---

## ðŸ‘©â€ðŸ’» Author
### Pranavi Kolipaka
Feel free to connect: 
- [LinkedIn] (https://www.linkedin.com/in/vns-sai-pranavi-kolipaka-489601208/) 
- [GitHub] (https://github.com/Pranavi2002)